### QIIME Workflow Overview
Raw Illumina Reads
Combine Paired end Reads
Make Mapping File
Make Barcode File 
Split libraries
Quality Filtering: Chimeras
Quality Filtering cont (filtering tables)
Discard chimeric OTUs
Remove OTUs observed in blanks
Remove singletons
Summarize tables
Diversity analysis
###

#Note, the file names might not be consistent, as I pulled this together from a couple different projects, and might have missed relabling some

### Notes on USEARCH61
The method I used for chimera checking and OTU creation during quality filtering was USEARCH61
USEARCH61 
Is not included in the qiime package, and must be downloaded and put into the macqiime directory
Is faster than ChimeraSlayer, and hasn’t caused me as many problems
Is the more recent pipeline for chimera checking created by the teams that made uchime and chimeraSlayer
The free version of USEARCH has a working memory limit of 3GB (the 6GB version costs 900$). So, the input files need to be split and processed separately before being recombined in larger projects, in order not to go over the USEARCH61 memory limit.Unless you have a small file size, in which case, no need to worry about that.
###

#Raw Illumina Reads
###
You should have three files
File one of sequence data (usually the forward reads)
Barcode information for each sequence (which sequence it belongs to)
File two of sequence data (usually the reverse reads)
To get a sense of overall quality of data, run the reads through FastQC
https://www.bioinformatics.babraham.ac.uk/projects/download.html
###

#Combine Paired end Reads
###
Qiime accepts only single end data (ie: forward primers), and you need to create a separate file for the barcode data
There are scripts to joins the forward and reverse reads by joining overlapping reads. Merging reads depends on the sizes of the sequence fragments.
Illumina read data are paired end (ie: forward and reverse primers)
Fastq-join is the simplest way to join paired end reads. FLASH is also good, but doesn’t work well if the reads are highly overlapping. FLASH is designed to merge pairs of reads when the original DNA fragments are shorter than twice the length of reads. The resulting longer reads can significantly improve genome assemblies.
https://expressionanalysis.github.io/ea-utils/

Here's the documentation for using fastq-join in QIIME
http://qiime.org/scripts/join_paired_ends.html
###

#Make Mapping File
###
#SampleID
BarcodeSequences
LinkerPrimerSequences 
However many columns of meta data you want
Last column: Description
Save as tab-delimited text file if you're making it in excell
###

validate_mapping_file.py -m map_16sdata.txt -o vmf-map/

#Make Barcode File
###
Use the grep function to search for the forward and reverse barcodes to determine barcode orientation. This is important for splitting the libraries.
Check to see where the barcodes are in the files, by using grep to search for the barcodes and color the files
Barcodes not in the mapping file will be excluded
Open the fastq sequence file in TextEdit to see its format
make sure the full.fasta does not use > instead of @. To fix the file’s format, open it in TextEdit and add the @ using find and replace
###

cat fullSequenceData.fasta |grep "CAGTTCAT"| wc -l
cat fullSequenceData.fasta |grep "ATGAACTG"| wc -l

cat fullSequenceData.fasta |grep "CAGTTCAT" --color=always| head
cat fullSequenceData.fasta |grep "ATGAACTG" --color=always| head

###
If unknown, barcodes can be extracted and put into its own file using the “extract_barcodes.py” script
-f, --fastq1
Input fastq filepath. This file is considered read 1.
-c, --input_type
Specify the input type. barcode_single_end: Input is a single fastq file, that starts with the barcode sequence. [default: barcode_single_end]
As we saw before using grep, this data is single end
-l, --bc1_len
Specify the length, in base pairs, of barcode 1. This applies to the –fastq1 file and all options specified by –input_type [default: 6]
Change this to 8bp
-m, --mapping_fp
Filepath of mapping file. NOTE: Must contain a header line indicating SampleID in the first column and BarcodeSequence in the second, LinkerPrimerSequence in the third and a ReversePrimer column before the final Description column. Needed for –attempt_read_orientation option. [default: None]
-o 
In the output directory, there will be fastq files (barcode file, and one or two reads files)
###

extract_barcodes.py -f fullSequenceData.fasta -o processed_seq/ -m map_16sdata.txt -l 8

#Split libraries
###
ie: match barcodes in map file to sequences, and get rid of sequences that don’t match your barcodes
Check your barcodes orientation before splitting libraries. If your samples have no barcodes, you can still analyze them using only alpha diversity. See Qiime documentation notes on making a maping file -b.

split_libraries_fastq.py
-i, --sequence_read_fps
The forward and reverse sequence read fastq files (comma-separated)
-o, --output_dir
Directory to store output files
-m, --mapping_fp
Metadata mapping file
-b, --barcode_type
The type of barcode used. This can be an integer, e.g. 6 for length 6 barcodes, or golay_12 for golay error-correcting barcodes. Error correction will only be applied for golay_12 barcodes [default: golay_12]
--barcode_type # if the barcodes are not 12 base pairs, where # is the size of the barcodes. 
Change this to 8, because out barcodes are 8bp long
###

split_libraries_fastq.py -o slout -i prossessed_seq/reads.fastq -b processed_seq/barcodes.fastq --barcode_type 8 -m map_16sdata.txt

#Cleaning data of primers
###
Primers are often removed from data sets, so that they do not appear more similar than they actually are (this is especially important if you are making a library or clusters using % identity, and you want high sensitivity)
There’s a “LinkerPrimerSequence” in the mapping file, and you can check to see if primers were removed from your data using the “grep” function again.
If you don’t have Geneius, you can do it by hand in Text edit (if you're a masochist), or use PRINSEQ to trim your sequences.
Replace ambiguous bases (anything that’s not ATCG) with “.” when you use the grep function to see if the primers are still there
###

cat file_name|grep "....GTGCCAGC.GCCGCGGTAA" --color=always| head 

#Quality Filtering: Chimeras
###
Using USEARCH 6.1 
Performs reference based chimera detection, like ChimeraSlayer, but also can perform de novo chimera detection based upon abundances of input sequences.
Chimeric sequences are expected to be in low frequency, so this allows for suspicious sequences to be double checked as chimeric if they don’t match a reference in a database. This is more important when dealing with novel populations.
The result of identify_chimeric_seqs.py is a text file that identifies which sequences are chimeric.
You then must filter your sequences to exclude these chimeric sequences
Sources:
http://qiime.org/scripts/identify_chimeric_seqs.html
http://qiime.org/1.8.0/tutorials/chimera_checking.html#usearch-6-1

Download usearch61
https://groups.google.com/forum/#!topic/qiime-forum/fXtD1CfsqMA
Download greengenes reference database for usearch
https://groups.google.com/forum/#!topic/qiime-forum/Qkprd1mR7c0
Rep_set/gg_97_otus_4feb2011.fasta
Put Usearch61 into correct macqiime folder, so that it is in your PATH
/macqiime/bin/usearch61
Use identify_chimeric_seq.py script
http://qiime.org/1.8.0/tutorials/chimera_checking.html#usearch-6-1

Input sequences should be demultiplexed sequences (e.g. output of split_libraries.py) that are not already clustered.
The reference database should not be aligned.
The reference sequences need to be in the same orientation as the query sequences. Use adjust_seq_orientation.py to reverse complement your reads if needed.
Chimera checking should be done first, followed by filtering chimeras out of the input reads, and these filtered sequences can then be clustered with pick_otus.py.

identify_chimeric_seqs.py -i slout/seqs.fna -m usearch61 -o usearch_chimeras -r gg_97_otus_4feb2011.fasta 
-i input sequences from split libraries
-m chimera detection method Chimera detection method. Choices: blast_fragments or ChimeraSlayer or usearch61. [default:ChimeraSlayer]
-r reference sequences Path to reference sequences (used to build a blast db when method blast_fragments or reference database for usearch61). [default: None; REQUIRED when method blast_fragments if no blast_db is provided, suppress requirement for usearch61 with –suppress_usearch61_ref;]
This takes about an hour
###

identify_chimeric_seqs.py -i slout/seqs.fna -m usearch61 -o usearch_chimeras -r gg_97_otus_4feb2011.fasta

#Quality Filtering cont (filtering tables)
###

Discard chimeric sequences by filtering all sequences ID as a chimera from the fasta file
ID chimeras: http://qiime.org/tutorials/chimera_checking.html
-n, --negate, Discard passed seq ids rather than keep passed seq ids. [default: False]
###

filter_fasta.py -f All_map/slout_all/seqs.fna -o seq_chimera.filtered_1 -s Map_1/usearch_chimeracheck_1/chimeras.txt -n

#Pick OTUs
###
Since USEARCH61 was used to pick the chimeras, qiime recommends using USEARCH61 again to pick the OTUs 
USEARCH61 can be used as an OTU picking method in qiime for picking open references
This step takes a while (6+hrs), so you might want to run it over night
Source
http://qiime.org/scripts/pick_open_reference_otus.html
http://qiime.org/1.8.0/tutorials/chimera_checking.html#usearch-6-1

pick_open_reference_otus.py -o otus_usearch61 -i seq_chimera.filtered_1 -p uc_fast_params.txt -m usearch61
-i, --input_fps
The input sequences filepath or comma-separated list of filepaths
-o, --output_dir
The output directory
-m, --otu_picking_method
The OTU picking method to use for reference and de novo steps. Passing usearch61, for example, means that usearch61 will be used for the de novo steps and usearch61_ref will be used for reference steps. [default: uclust]
-p uc_fast_params.txt 
Here, this parameter file tells the computer to allow sequences to match the reference database if either their forward or reverse orientation matches to a reference sequence
Reference: http://qiime.org/documentation/file_formats.html#qiime-parameters 
###

pick_open_reference_otus.py -o otus_usearch61 -i seq_chimera.filtered_1 -p uc_fast_params.txt -m usearch61
-i, --input_fps

# Remove Singletons from Data Set
filter_samples_from_otu_table.py -i otu_table_non_chimeric_minus_contaminants.biom -o final_otu_table_non_chimeric_minus_contaminants.biom -n 1

#Remove OTUs observed in blanks
###
Filter by sample type, according to your mapping file, to get rid of reads which occur in your blank sample, thus are contamination:
###
filter_samples_from_otu_table.py –i otu_table_non_chimeric.biom -o otu_table_non_chimeric_blank_samples.biom -m map.txt -s "Sample_Type:Blank”

###
Now, filter out any singletons left when these reads have been removed:
-n, --min_count = The minimum total observation count of an otu for that otu to be retained [default: 0]
###
filter_otus_from_otu_table.py -i otu_table_non_chimeric_blank_samples.biom -o filtered_otu_table_blank_samples.biom -n 1

#Summarize tables
###
The final OTU table can then be summarized:
You need to do this to get the minimum value of counts for core diversity analysis 
###
biom summarize-table -i otus_usearch61/otu_table_mc2_w_tax.biom 

#Diversity analysis
###
-Alpha
Diversity in one dataset (ie: specie richness and evenness at one place) 
Several measures of diversity possible with alpha_rarefaction.py
Common measures include Chao1 (estimator of richness), observed species (observed richness), Shannon index (estimates richness and evenness), Phylogenetic Diversity (how taxonomically diverse a sample is), Simpson index (evenness/dominance)
First create a parameters file listing the measures you want:
echo alpha_diversity:metricschao1,observed_species,shannon,PD_whole_tree > alpha_params.txt
Rarefraction Curve
-Beta
Diversity at more than one dataset compared to each other (ie: comparing specie richness and eveness between places)
PCoA plots

Qiime defaults to genus (L6) taxa identification
To get specie level (L7) identification, you have to create a parameter file to tell the program to do that. Just, know Qiime isn't that accurate past the genus level, but then that's why we have metagenomics.
Below is the parameter file I made to use with summarizing taxa in the core_diversity.py script
Source:
http://qiime.org/documentation/qiime_parameters_files.html
Summarize_taxa:level 2,3,4,5,6,7
###

core_diversity_analyses.py -o cdout_usearch61_yestree_paramL7 -i otus_usearch61/otu_table_mc2_w_tax_no_pynast_failures.biom -m All_map/map_16sdata.txt -e 30111 -t otus_usearch61/rep_set.tre -p L7taxa_param.txt

make_emperor.py -i cdout_usearch61_yestree_paramL7/bdiv_even30111/weighted_unifrac_pc.txt -o cdout_usearch61_yestree_paramL7/bdiv_even30111/weighted_unifrac_emperor_pcoa_plot/ -m All_map/map_16sdata.txt 

make_emperor.py -i cdout_usearch61_yestree_paramL7/bdiv_even30111/unweighted_unifrac_pc.txt -o cdout_usearch61_yestree_paramL7/bdiv_even30111/unweighted_unifrac_emperor_pcoa_plot/ -m All_map/map_16sdata.txt 

###
So, at the end of this, you should have 
OTU tables, phylogenetic tree, Taxa plots up to the specie level, and alpha and beta diversity analysis
###



